{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e782dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gliner==0.1.12 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.1.12)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gliner==0.1.12) (2.3.0+cu121)\n",
      "Requirement already satisfied: transformers>=4.38.2 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gliner==0.1.12) (4.41.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.4 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gliner==0.1.12) (0.23.4)\n",
      "Requirement already satisfied: flair==0.13.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gliner==0.1.12) (0.13.1)\n",
      "Requirement already satisfied: scipy<=1.12 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gliner==0.1.12) (1.12.0)\n",
      "Requirement already satisfied: seqeval in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gliner==0.1.12) (1.2.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gliner==0.1.12) (4.66.4)\n",
      "Requirement already satisfied: boto3>=1.20.27 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (1.35.13)\n",
      "Requirement already satisfied: bpemb>=0.3.2 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (0.3.5)\n",
      "Requirement already satisfied: conllu>=4.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (5.0.1)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (1.2.14)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (6.2.3)\n",
      "Requirement already satisfied: gdown>=4.4.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (5.2.0)\n",
      "Requirement already satisfied: gensim>=4.2.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (4.3.3)\n",
      "Requirement already satisfied: janome>=0.4.2 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (0.5.0)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (5.2.2)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (3.9.0)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (10.5.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pjh37\\appdata\\roaming\\python\\python312\\site-packages (from flair==0.13.1->gliner==0.1.12) (2.9.0.post0)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (0.2.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (2024.5.15)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (1.5.1)\n",
      "Requirement already satisfied: segtok>=1.5.11 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (0.9.0)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (0.4.0)\n",
      "Collecting urllib3<2.0.0,>=1.0.0 (from flair==0.13.1->gliner==0.1.12)\n",
      "  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (0.7.1)\n",
      "Requirement already satisfied: semver<4.0.0,>=3.0.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from flair==0.13.1->gliner==0.1.12) (3.0.2)\n",
      "Requirement already satisfied: numpy<1.29.0,>=1.22.4 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scipy<=1.12->gliner==0.1.12) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.38.2->gliner==0.1.12) (3.15.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pjh37\\appdata\\roaming\\python\\python312\\site-packages (from transformers>=4.38.2->gliner==0.1.12) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.38.2->gliner==0.1.12) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.38.2->gliner==0.1.12) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.38.2->gliner==0.1.12) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.38.2->gliner==0.1.12) (0.4.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.4->gliner==0.1.12) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.21.4->gliner==0.1.12) (4.12.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair==0.13.1->gliner==0.1.12) (0.2.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]<5.0.0,>=4.18.0->flair==0.13.1->gliner==0.1.12) (4.25.3)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.13 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3>=1.20.27->flair==0.13.1->gliner==0.1.12) (1.35.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3>=1.20.27->flair==0.13.1->gliner==0.1.12) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from boto3>=1.20.27->flair==0.13.1->gliner==0.1.12) (0.10.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pjh37\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->flair==0.13.1->gliner==0.1.12) (1.16.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deprecated>=1.2.13->flair==0.13.1->gliner==0.1.12) (1.16.0)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in c:\\users\\pjh37\\appdata\\roaming\\python\\python312\\site-packages (from ftfy>=6.1.0->flair==0.13.1->gliner==0.1.12) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gdown>=4.4.0->flair==0.13.1->gliner==0.1.12) (4.12.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gensim>=4.2.0->flair==0.13.1->gliner==0.1.12) (7.0.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.13.1->gliner==0.1.12) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.13.1->gliner==0.1.12) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.13.1->gliner==0.1.12) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.13.1->gliner==0.1.12) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.13.1->gliner==0.1.12) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=2.2.3->flair==0.13.1->gliner==0.1.12) (3.1.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mpld3>=0.3->flair==0.13.1->gliner==0.1.12) (3.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.0.2->flair==0.13.1->gliner==0.1.12) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.0.2->flair==0.13.1->gliner==0.1.12) (3.5.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->gliner==0.1.12) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->gliner==0.1.12) (3.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2.0.0->gliner==0.1.12) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->gliner==0.1.12) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=2.0.0->gliner==0.1.12) (2021.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\pjh37\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->gliner==0.1.12) (0.4.6)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers>=4.38.2->gliner==0.1.12) (0.34.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\pjh37\\appdata\\roaming\\python\\python312\\site-packages (from accelerate>=0.21.0->transformers>=4.38.2->gliner==0.1.12) (5.9.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from beautifulsoup4->gdown>=4.4.0->flair==0.13.1->gliner==0.1.12) (2.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->mpld3>=0.3->flair==0.13.1->gliner==0.1.12) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers>=4.38.2->gliner==0.1.12) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers>=4.38.2->gliner==0.1.12) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers>=4.38.2->gliner==0.1.12) (2024.6.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests[socks]->gdown>=4.4.0->flair==0.13.1->gliner==0.1.12) (1.7.1)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=2.0.0->gliner==0.1.12) (1.3.0)\n",
      "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.5.0\n",
      "    Uninstalling urllib3-2.5.0:\n",
      "      Successfully uninstalled urllib3-2.5.0\n",
      "Successfully installed urllib3-1.26.20\n"
     ]
    }
   ],
   "source": [
    "!pip install gliner==0.1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdc83192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3 in c:\\users\\pjh37\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.20)\n",
      "Collecting urllib3\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.20\n",
      "    Uninstalling urllib3-1.26.20:\n",
      "      Successfully uninstalled urllib3-1.26.20\n",
      "Successfully installed urllib3-2.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flair 0.13.1 requires urllib3<2.0.0,>=1.0.0, but you have urllib3 2.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ac623d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36077f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pjh37\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "c:\\Users\\pjh37\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = GLiNER.from_pretrained(\"numind/NuZero_token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab57548",
   "metadata": {},
   "source": [
    "## 1. Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "554d6e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "df_2023 = pd.read_csv('Data/wearable_devices_processed_2023.csv', usecols=['cleaned_abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecc6cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중복 토큰 제거\n",
    "def remove_duplicates(text):\n",
    "    words = text.split()\n",
    "    unique_words = []\n",
    "    seen = set()\n",
    "    for word in words:\n",
    "        if word not in seen:\n",
    "            unique_words.append(word)\n",
    "            seen.add(word)\n",
    "    return ' '.join(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b2575f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>remove_duplicates_abstract</th>\n",
       "      <th>remove_duplicates_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one embodiment directed system enabling two us...</td>\n",
       "      <td>one embodiment directed system enabling two us...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one embodiment directed system enabling two us...</td>\n",
       "      <td>one embodiment directed system enabling two us...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>system method managing temperature wearable de...</td>\n",
       "      <td>system method managing temperature wearable de...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>provided herein digital care circle platform e...</td>\n",
       "      <td>provided herein digital care circle platform e...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>method device wired charging communication wea...</td>\n",
       "      <td>method device wired charging communication wea...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cleaned_abstract  \\\n",
       "0  one embodiment directed system enabling two us...   \n",
       "1  one embodiment directed system enabling two us...   \n",
       "2  system method managing temperature wearable de...   \n",
       "3  provided herein digital care circle platform e...   \n",
       "4  method device wired charging communication wea...   \n",
       "\n",
       "                          remove_duplicates_abstract  remove_duplicates_token  \n",
       "0  one embodiment directed system enabling two us...                       41  \n",
       "1  one embodiment directed system enabling two us...                       41  \n",
       "2  system method managing temperature wearable de...                       25  \n",
       "3  provided herein digital care circle platform e...                       42  \n",
       "4  method device wired charging communication wea...                       27  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the function to the cleaned_abstract column\n",
    "df_2023['remove_duplicates_abstract'] = df_2023['cleaned_abstract'].apply(remove_duplicates)\n",
    "\n",
    "# 초록 토큰 수 계산\n",
    "df_2023['remove_duplicates_token'] = df_2023['remove_duplicates_abstract'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# 결과 출력\n",
    "df_2023.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c7c0733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [arena, prelearning, sea, ssb, rmsi, education...\n",
       "1    [pfl, paneltouch, reauthenticating, pixellevel...\n",
       "2    [straight, import, inktoner, warranty, draft, ...\n",
       "3    [predecoded, timevarying, since, reestablishin...\n",
       "4    [trailer, fall, hump, psf, keratinoytes, amorp...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 행을 하나의 문자열로 결합\n",
    "combined_text = ' '.join(df_2023['remove_duplicates_abstract'])\n",
    "\n",
    "# 공백으로 토큰화하여 중복 제거\n",
    "tokens = combined_text.split()\n",
    "unique_tokens = set(tokens)  # set을 사용하여 중복을 제거\n",
    "unique_tokens_list = list(unique_tokens)  # DataFrame에 저장하기 전에 리스트로 변환\n",
    "\n",
    "# 중복이 제거된 토큰들을 공백으로 다시 연결\n",
    "final_text = ' '.join(unique_tokens)\n",
    "\n",
    "# 한 행당 384개의 토큰으로 저장(NuNER max token)\n",
    "chunk_size = 384\n",
    "rows = [unique_tokens_list[i:i + chunk_size] for i in range(0, len(unique_tokens_list), chunk_size)]\n",
    "\n",
    "# DataFrame 생성\n",
    "unique_df = pd.DataFrame({\"tokens\": rows})\n",
    "\n",
    "# DataFrame 결과 확인\n",
    "unique_df['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7b71d",
   "metadata": {},
   "source": [
    "## 2. Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8fb3d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "file_path_2023_topic_8 = 'Data/wearable_devices_2023_lda_topic_8_with_labels.csv'\n",
    "file_path_2023_topic_12 = 'Data/wearable_devices_2023_lda_topic_12_with_labels.csv'\n",
    "file_path_2023_topic_16 = 'Data/wearable_devices_2023_lda_topic_16_with_labels.csv'\n",
    "\n",
    "data_2023_topic_8 = pd.read_csv(file_path_2023_topic_8)\n",
    "data_2023_topic_12 = pd.read_csv(file_path_2023_topic_12)\n",
    "data_2023_topic_16 = pd.read_csv(file_path_2023_topic_16)\n",
    "\n",
    "# 'label' 열만 선택하여 dimension 추출\n",
    "label_2023_topic_8 = pd.DataFrame(data_2023_topic_8['label'])\n",
    "label_2023_topic_12 = pd.DataFrame(data_2023_topic_12['label'])\n",
    "label_2023_topic_16 = pd.DataFrame(data_2023_topic_16['label'])\n",
    "\n",
    "# NuZero requires labels to be lower-cased\n",
    "label_2023_topic_8 = label_2023_topic_8['label'].str.lower()\n",
    "label_2023_topic_12 = label_2023_topic_12['label'].str.lower()\n",
    "label_2023_topic_16 = label_2023_topic_16['label'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aab53ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           data processing\n",
       "1    wireless communication\n",
       "2            user interface\n",
       "3              audio system\n",
       "4        optical technology\n",
       "5                 materials\n",
       "6            network system\n",
       "7                   sensors\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "label_2023_topic_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e493b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            data processing\n",
       "1     wireless communication\n",
       "2               applications\n",
       "3                    sensors\n",
       "4             user interface\n",
       "5           external devices\n",
       "6             network system\n",
       "7                    display\n",
       "8               audio system\n",
       "9         optical technology\n",
       "10                 materials\n",
       "11                    memory\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "label_2023_topic_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "995bee47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             user interface\n",
       "1      wireless signal setup\n",
       "2                    circuit\n",
       "3            medical devices\n",
       "4               audio system\n",
       "5                      power\n",
       "6             network system\n",
       "7                    display\n",
       "8                     memory\n",
       "9            data processing\n",
       "10     display manufacturing\n",
       "11             semiconductor\n",
       "12                 emergency\n",
       "13    wireless communication\n",
       "14                   sensors\n",
       "15          external devices\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 확인\n",
    "label_2023_topic_16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e30c8b",
   "metadata": {},
   "source": [
    "### 1) Topic = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57435518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio system</td>\n",
       "      <td>earbuds, earbud, earphone, microphone, speaker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data processing</td>\n",
       "      <td>bytestream, datastreaming, datahandling, pipel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>materials</td>\n",
       "      <td>iridium, hexylammonium, graphite, glassceramic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>network system</td>\n",
       "      <td>ethernet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>optical technology</td>\n",
       "      <td>nearinfrared, waveguide, fiberoptic, lightscat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Label                                               Text\n",
       "0        audio system  earbuds, earbud, earphone, microphone, speaker...\n",
       "1     data processing  bytestream, datastreaming, datahandling, pipel...\n",
       "2           materials  iridium, hexylammonium, graphite, glassceramic...\n",
       "3      network system                                           ethernet\n",
       "4  optical technology  nearinfrared, waveguide, fiberoptic, lightscat..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출 결과를 저장할 리스트\n",
    "results_2023_topic_8_entity = []\n",
    "\n",
    "# 각 텍스트에 대해 엔티티 추출\n",
    "for tokens in unique_df['tokens']:\n",
    "    if isinstance(tokens, list):\n",
    "        text = ' '.join(tokens)\n",
    "    else:\n",
    "        text = str(tokens)\n",
    "\n",
    "    entities = model.predict_entities(text, label_2023_topic_8)\n",
    "\n",
    "    for entity in entities:\n",
    "        #print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "        results_2023_topic_8_entity.append({\n",
    "            'Text': entity['text'],\n",
    "            'Label': entity['label']\n",
    "        })\n",
    "\n",
    "# 결과 리스트를 데이터 프레임으로 변환\n",
    "df_2023_topic_8_entity = pd.DataFrame(results_2023_topic_8_entity)\n",
    "\n",
    "# Label별로 Text를 합치기\n",
    "df_2023_topic_8_grouped = df_2023_topic_8_entity.groupby('Label')['Text'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "# 결과 데이터 프레임 출력\n",
    "df_2023_topic_8_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd18538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "output_file_2023_topic_8 = 'Data/wearable_devices_2023_lda_topic_8_entities.csv'\n",
    "df_2023_topic_8_grouped.to_csv(output_file_2023_topic_8, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce16d3b9",
   "metadata": {},
   "source": [
    "### 2) Topic = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd77206a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>applications</td>\n",
       "      <td>watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audio system</td>\n",
       "      <td>headphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data processing</td>\n",
       "      <td>bytestream, datastreaming, datahandling, beamf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>display</td>\n",
       "      <td>microdisplays, lcd, microdisplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>external devices</td>\n",
       "      <td>smartwatches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Label                                               Text\n",
       "0      applications                                              watch\n",
       "1      audio system                                          headphone\n",
       "2   data processing  bytestream, datastreaming, datahandling, beamf...\n",
       "3           display                   microdisplays, lcd, microdisplay\n",
       "4  external devices                                       smartwatches"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출 결과를 저장할 리스트\n",
    "results_2023_topic_12_entity = []\n",
    "\n",
    "# 각 텍스트에 대해 엔티티 추출\n",
    "for tokens in unique_df['tokens']:\n",
    "    if isinstance(tokens, list):\n",
    "        text = ' '.join(tokens)\n",
    "    else:\n",
    "        text = str(tokens)\n",
    "\n",
    "    entities = model.predict_entities(text, label_2023_topic_12)\n",
    "\n",
    "    for entity in entities:\n",
    "        #print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "        results_2023_topic_12_entity.append({\n",
    "            'Text': entity['text'],\n",
    "            'Label': entity['label']\n",
    "        })\n",
    "\n",
    "# 결과 리스트를 데이터 프레임으로 변환\n",
    "df_2023_topic_12_entity = pd.DataFrame(results_2023_topic_12_entity)\n",
    "\n",
    "# Label별로 Text를 합치기\n",
    "df_2023_topic_12_grouped = df_2023_topic_12_entity.groupby('Label')['Text'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "# 결과 데이터 프레임 출력\n",
    "df_2023_topic_12_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bec4f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "output_file_2023_topic_12 = 'Data/wearable_devices_2023_lda_topic_12_entities.csv'\n",
    "df_2023_topic_12_grouped.to_csv(output_file_2023_topic_12, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81e33a",
   "metadata": {},
   "source": [
    "### 3) Topic = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a968510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>audio system</td>\n",
       "      <td>headphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>circuit</td>\n",
       "      <td>udi, circuit, capacitor, subcircuits, circuitry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data processing</td>\n",
       "      <td>bytestream, datastreaming, datahandling, beamf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>display</td>\n",
       "      <td>lcd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medical devices</td>\n",
       "      <td>inktoner, condom, cigarette, earbuds, oximeter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label                                               Text\n",
       "0     audio system                                          headphone\n",
       "1          circuit    udi, circuit, capacitor, subcircuits, circuitry\n",
       "2  data processing  bytestream, datastreaming, datahandling, beamf...\n",
       "3          display                                                lcd\n",
       "4  medical devices  inktoner, condom, cigarette, earbuds, oximeter..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 추출 결과를 저장할 리스트\n",
    "results_2023_topic_16_entity = []\n",
    "\n",
    "# 각 텍스트에 대해 엔티티 추출\n",
    "for tokens in unique_df['tokens']:\n",
    "    if isinstance(tokens, list):\n",
    "        text = ' '.join(tokens)\n",
    "    else:\n",
    "        text = str(tokens)\n",
    "\n",
    "    entities = model.predict_entities(text, label_2023_topic_16)\n",
    "\n",
    "    for entity in entities:\n",
    "        #print(entity[\"text\"], \"=>\", entity[\"label\"])\n",
    "        results_2023_topic_16_entity.append({\n",
    "            'Text': entity['text'],\n",
    "            'Label': entity['label']\n",
    "        })\n",
    "\n",
    "# 결과 리스트를 데이터 프레임으로 변환\n",
    "df_2023_topic_16_entity = pd.DataFrame(results_2023_topic_16_entity)\n",
    "\n",
    "# Label별로 Text를 합치기\n",
    "df_2023_topic_16_grouped = df_2023_topic_16_entity.groupby('Label')['Text'].apply(lambda x: ', '.join(x)).reset_index()\n",
    "\n",
    "# 결과 데이터 프레임 출력\n",
    "df_2023_topic_16_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82a207d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "output_file_2023_topic_16 = 'Data/wearable_devices_2023_lda_topic_16_entities.csv'\n",
    "df_2023_topic_16_grouped.to_csv(output_file_2023_topic_16, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
